{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ejD5lOnLpGJl"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QN3hso7IpaUQ",
        "outputId": "3a941c0a-1aed-49b3-fd83-68100047a91c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1979"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"/home/mohe/Downloads/xenophobic_data (1).csv\")\n",
        "data[\"tweet\"] = data[\"tweet\"].astype(str)\n",
        "\n",
        "delete_fraction = 0.9\n",
        "\n",
        "label_0_df = data[data['label'] == 0]\n",
        "\n",
        "num_rows_to_delete = int(delete_fraction * len(label_0_df))\n",
        "rows_to_delete = label_0_df.sample(n=num_rows_to_delete, random_state=42)\n",
        "\n",
        "data = data.drop(rows_to_delete.index).reset_index()\n",
        "len(data[data[\"label\"] == 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "i7WY31gWp8J1"
      },
      "outputs": [],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "class TextVectorizer:\n",
        "\n",
        "  def __init__(self, sequence_length, vocab_size, target=False):\n",
        "    self.target = target\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.vocab_counter = Counter()\n",
        "    self.stoi = {\"[pad]\": 0, \"[start]\": 1, \"[end]\": 2, \"[UNK]\": 3}\n",
        "    self.itos = {0: \"[pad]\", 1: \"[start]\", 2: \"[end]\", 3: \"[UNK]\"}\n",
        "\n",
        "  def standardize(self, text):\n",
        "    text = text.lower()\n",
        "    return \"\".join(char for char in text\n",
        "                  if char not in strip_chars)\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    text = self.standardize(text)\n",
        "    return text.split()\n",
        "\n",
        "  def adapt(self, dataset):\n",
        "    for text in tqdm(dataset):\n",
        "      tokens = self.tokenize(text)\n",
        "      for token in tokens:\n",
        "        self.vocab_counter[token] += 1\n",
        "\n",
        "    for token, _ in self.vocab_counter.most_common(self.vocab_size):\n",
        "      indx = len(self.stoi)\n",
        "      self.stoi[token] = indx\n",
        "      self.itos[indx] = token\n",
        "\n",
        "  def encode(self, text):\n",
        "    text = self.standardize(text)\n",
        "    tokens = self.tokenize(text)\n",
        "    if self.target:\n",
        "      result = ([self.stoi[\"[start]\"]] + [self.stoi.get(token, 3) for token in tokens]\n",
        "            + [self.stoi[\"[end]\"]])\n",
        "    else:\n",
        "      result = [self.stoi.get(token, 3) for token in tokens]\n",
        "\n",
        "    if len(result) <= self.sequence_length:\n",
        "        pad_size = self.sequence_length - len(result)\n",
        "        result += [self.stoi.get(\"[pad]\")] * (pad_size)\n",
        "    else:\n",
        "      #truncate!\n",
        "      result = result[:self.sequence_length]\n",
        "\n",
        "    return result\n",
        "\n",
        "  def decode(self, int_sequence):\n",
        "    return \" \".join(self.itos.get(i, \"[UNK]\") for i in int_sequence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "9L59EFH-qbfF"
      },
      "outputs": [],
      "source": [
        "vocab_size = 9000\n",
        "sequence_length = 50\n",
        "\n",
        "vectorizer = TextVectorizer(sequence_length, vocab_size, target=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ3gplPTq0Ho",
        "outputId": "0bf5cfd4-d729-409b-c348-f3858dd382d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3864 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3864/3864 [00:00<00:00, 59168.95it/s]\n"
          ]
        }
      ],
      "source": [
        "vectorizer.adapt(data[\"tweet\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "ERbIfk-osVDS"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, vectorizer):\n",
        "        self.data = data\n",
        "        self.vectorizer = vectorizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      text = self.data.iloc[idx][\"tweet\"]\n",
        "      label = self.data.iloc[idx][\"label\"]\n",
        "      text = self.vectorizer.encode(text)\n",
        "      return (torch.tensor(text).long(),\n",
        "              torch.tensor(label).long())\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "G0wWCenHtaGe"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "num_val_samples = int(0.15 * len(data))\n",
        "num_train_samples = len(data) - 2 * num_val_samples\n",
        "\n",
        "train_pairs = data[:num_train_samples]\n",
        "val_pairs = data[num_train_samples:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZtLNoaIx4JS",
        "outputId": "b5ad80e1-29cf-4a1c-9f4a-fc369e991dc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2706, 1158)"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_pairs[\"tweet\"].size, val_pairs[\"tweet\"].size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "gAU6BPH1t-YP"
      },
      "outputs": [],
      "source": [
        "train_ds = TextDataset(train_pairs, vectorizer)\n",
        "val_ds = TextDataset(val_pairs, vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "TEfvaK-zuXme"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
        "val_dl = DataLoader(val_ds, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "u2B_Z5z1QD9x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   1,  512, 2994,  ...,    0,    0,    0],\n",
            "        [   1, 4894,    6,  ...,    0,    0,    0],\n",
            "        [   1,  868,   54,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   1,   36,  163,  ...,    0,    0,    0],\n",
            "        [   1,   40,   17,  ...,    0,    0,    0],\n",
            "        [   1, 3182,   24,  ...,    0,    0,    0]])\n",
            "tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
            "        0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0])\n"
          ]
        }
      ],
      "source": [
        "for text, label in train_dl:\n",
        "    print(text)\n",
        "    print(label)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHF6y0ApuqjC",
        "outputId": "cc37df43-fee6-4877-b0b5-d537cd093498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8715)\n"
          ]
        }
      ],
      "source": [
        "a = 0\n",
        "for text, label in train_dl:\n",
        "  if a < torch.max(text):\n",
        "    a = torch.max(text)\n",
        "\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "nIuCZLQG6vIn"
      },
      "outputs": [],
      "source": [
        "class BiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, dropout=0.5):\n",
        "        super(BiLSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim *2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  \n",
        "        lstm_out, _= self.lstm(x) \n",
        "        x = lstm_out[:, -1, :]  \n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)  \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "Zv0ZnOqaywkx",
        "outputId": "936ebbcb-f464-413a-acfd-fb3b8116f40c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/43 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:04<00:00,  9.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4 - Loss: 0.7969 - Train: 0.5000\n",
            "Loss: 0.6739 - Validation: 0.5285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:04<00:00,  9.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/4 - Loss: 0.6691 - Train: 0.5924\n",
            "Loss: 0.6080 - Validation: 0.6511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:04<00:00,  9.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/4 - Loss: 0.6222 - Train: 0.6608\n",
            "Loss: 0.3673 - Validation: 0.8679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:05<00:00,  7.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/4 - Loss: 0.2924 - Train: 0.9047\n",
            "Loss: 0.2297 - Validation: 0.9240\n"
          ]
        }
      ],
      "source": [
        "LR = 2e-2\n",
        "NUM_EPOCHS = 4\n",
        "embedding_dim = 100  \n",
        "hidden_dim = 256  \n",
        "output_dim = 1  \n",
        "num_layers = 2\n",
        "\n",
        "model = BiLSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# device = torch.device('cpu')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for text, label in tqdm(train_dl):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = text.to(device)\n",
        "        labels = label.float().unsqueeze(1).to(device)\n",
        "\n",
        "        outputs = model(input_ids)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        predicted = torch.round(torch.sigmoid(outputs))\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dl)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Loss: {epoch_loss:.4f} - Train: {epoch_accuracy:.4f}\")\n",
        "    \n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text, label in (val_dl):\n",
        "            input_ids = text.to(device)\n",
        "            labels = label.float().unsqueeze(1).to(device)\n",
        "\n",
        "            outputs = model(input_ids)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            predicted = torch.round(torch.sigmoid(outputs))\n",
        "            val_correct_predictions += (predicted == labels).sum().item()\n",
        "            val_total_predictions += labels.size(0)\n",
        "\n",
        "            val_running_loss += loss.item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(val_dl)\n",
        "    val_epoch_accuracy = val_correct_predictions / val_total_predictions\n",
        "\n",
        "    print(f\"Loss: {val_epoch_loss:.4f} - Validation: {val_epoch_accuracy:.4f}\")\n",
        "    \n",
        "    model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
